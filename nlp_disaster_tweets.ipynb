{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0820a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2052ba",
   "metadata": {},
   "source": [
    "# Training it on combined keyword + tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8326e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "train = pd.read_csv('/Users/yunjuha/Downloads/nlp-getting-started/train.csv')\n",
    "train_df = pd.DataFrame(train)\n",
    "train_df = train_df.dropna(subset=['keyword'])\n",
    "\n",
    "selected_columns = ['keyword', 'text', 'target']\n",
    "train_df = train_df[selected_columns]\n",
    "train_df['combined'] = train_df['keyword'] + \" \" + train_df['text']\n",
    "train_df.drop(['keyword', 'text'], axis=1, inplace=True)\n",
    "\n",
    "#test data\n",
    "test = pd.read_csv('/Users/yunjuha/Downloads/nlp-getting-started/test.csv')\n",
    "test_df = pd.DataFrame(test)\n",
    "test_df = test_df.dropna(subset=['keyword'])\n",
    "\n",
    "selected_columns = ['keyword', 'text']\n",
    "test_df = test_df[selected_columns]\n",
    "test_df['combined'] = test_df['keyword'] + \" \" + test_df['text']\n",
    "test_df.drop(['keyword', 'text'], axis=1, inplace=True)\n",
    "test_df['target'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b85aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8047650562541363\n",
      "Precision: 0.7888513513513513\n",
      "Recall: 0.7331240188383046\n",
      "F1 Score: 0.7599674532139951\n",
      "Confusion Matrix:\n",
      "[[749 125]\n",
      " [170 467]]\n"
     ]
    }
   ],
   "source": [
    "#TRAINING MODEL\n",
    "\n",
    "X_combined = train_df['combined']\n",
    "y = train_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#TF-IDF vectorization on combined text\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622ce9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ablaze Birmingham Wholesale Market is ablaze B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ablaze @sunkxssedharry will you wear shorts fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ablaze #PreviouslyOnDoyinTv: Toke MakinwaÛªs ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ablaze Check these out: http://t.co/rOI2NSmEJJ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ablaze PSA: IÛªm splitting my personalities.\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>wrecked RT CNBC '3 words from Disney CEO Bob I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>wrecked Smackdown tyme this should put me in a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>wrecked @thrillhho jsyk I haven't stopped thin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>wrecked @stighefootball Begovic has been garba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>wrecked Wrecked today got my hattrick ????</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3237 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               combined  target\n",
       "15    ablaze Birmingham Wholesale Market is ablaze B...       0\n",
       "16    ablaze @sunkxssedharry will you wear shorts fo...       0\n",
       "17    ablaze #PreviouslyOnDoyinTv: Toke MakinwaÛªs ...       1\n",
       "18    ablaze Check these out: http://t.co/rOI2NSmEJJ...       0\n",
       "19    ablaze PSA: IÛªm splitting my personalities.\\...       0\n",
       "...                                                 ...     ...\n",
       "3247  wrecked RT CNBC '3 words from Disney CEO Bob I...       0\n",
       "3248  wrecked Smackdown tyme this should put me in a...       0\n",
       "3249  wrecked @thrillhho jsyk I haven't stopped thin...       0\n",
       "3250  wrecked @stighefootball Begovic has been garba...       0\n",
       "3251         wrecked Wrecked today got my hattrick ????       0\n",
       "\n",
       "[3237 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TESTING MODEL\n",
    "\n",
    "X_test = test_df['combined']\n",
    "y_test = test_df['target']\n",
    "\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "test_df['target'] = y_pred\n",
    "combined_test_df = test_df\n",
    "\n",
    "combined_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a093be",
   "metadata": {},
   "source": [
    "# Separating keyword and tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3f76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "train = pd.read_csv('/Users/yunjuha/Downloads/nlp-getting-started/train.csv')\n",
    "train_df = pd.DataFrame(train)\n",
    "train_df = train_df.dropna(subset=['keyword'])\n",
    "\n",
    "#test data\n",
    "test = pd.read_csv('/Users/yunjuha/Downloads/nlp-getting-started/test.csv')\n",
    "test_df = pd.DataFrame(test)\n",
    "test_df = test_df.dropna(subset=['keyword'])\n",
    "test_df['target'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab5d383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7921906022501655\n",
      "Precision: 0.7609046849757674\n",
      "Recall: 0.7394034536891679\n",
      "F1 Score: 0.75\n",
      "Confusion Matrix:\n",
      "[[726 148]\n",
      " [166 471]]\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "\n",
    "X = train_df[['keyword', 'text']]\n",
    "y = train_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tfidf_vectorizer_keyword = TfidfVectorizer()\n",
    "tfidf_vectorizer_tweet = TfidfVectorizer()\n",
    "\n",
    "X_train_keyword_tfidf = tfidf_vectorizer_keyword.fit_transform(X_train['keyword'])\n",
    "X_train_tweet_tfidf = tfidf_vectorizer_tweet.fit_transform(X_train['text'])\n",
    "\n",
    "import scipy.sparse\n",
    "\n",
    "X_train_combined_tfidf = scipy.sparse.hstack((X_train_keyword_tfidf, X_train_tweet_tfidf))\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_combined_tfidf, y_train)\n",
    "\n",
    "X_test_keyword_tfidf = tfidf_vectorizer_keyword.transform(X_test['keyword'])\n",
    "X_test_tweet_tfidf = tfidf_vectorizer_tweet.transform(X_test['text'])\n",
    "\n",
    "X_test_combined_tfidf = scipy.sparse.hstack((X_test_keyword_tfidf, X_test_tweet_tfidf))\n",
    "\n",
    "y_pred = clf.predict(X_test_combined_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08f861c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>46</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London</td>\n",
       "      <td>Birmingham Wholesale Market is ablaze BBC News...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>47</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Niall's place | SAF 12 SQUAD |</td>\n",
       "      <td>@sunkxssedharry will you wear shorts for race ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>51</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NIGERIA</td>\n",
       "      <td>#PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>58</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Live On Webcam</td>\n",
       "      <td>Check these out: http://t.co/rOI2NSmEJJ http:/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Los Angeles, Califnordia</td>\n",
       "      <td>PSA: IÛªm splitting my personalities.\\n\\n?? t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>10806</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Seattle Washington</td>\n",
       "      <td>RT CNBC '3 words from Disney CEO Bob Iger wrec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>10807</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Acey mountain islanddåÇTorontoåÈ</td>\n",
       "      <td>Smackdown tyme this should put me in a good mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>10816</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>@thrillhho jsyk I haven't stopped thinking abt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>10820</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Brussels, Belgium</td>\n",
       "      <td>@stighefootball Begovic has been garbage. He g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>10828</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wrecked today got my hattrick ????</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3237 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword                          location  \\\n",
       "15       46   ablaze                            London   \n",
       "16       47   ablaze    Niall's place | SAF 12 SQUAD |   \n",
       "17       51   ablaze                           NIGERIA   \n",
       "18       58   ablaze                    Live On Webcam   \n",
       "19       60   ablaze          Los Angeles, Califnordia   \n",
       "...     ...      ...                               ...   \n",
       "3247  10806  wrecked                Seattle Washington   \n",
       "3248  10807  wrecked  Acey mountain islanddåÇTorontoåÈ   \n",
       "3249  10816  wrecked                       los angeles   \n",
       "3250  10820  wrecked                 Brussels, Belgium   \n",
       "3251  10828  wrecked                               NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "15    Birmingham Wholesale Market is ablaze BBC News...       0  \n",
       "16    @sunkxssedharry will you wear shorts for race ...       0  \n",
       "17    #PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...       1  \n",
       "18    Check these out: http://t.co/rOI2NSmEJJ http:/...       0  \n",
       "19    PSA: IÛªm splitting my personalities.\\n\\n?? t...       0  \n",
       "...                                                 ...     ...  \n",
       "3247  RT CNBC '3 words from Disney CEO Bob Iger wrec...       0  \n",
       "3248  Smackdown tyme this should put me in a good mo...       0  \n",
       "3249  @thrillhho jsyk I haven't stopped thinking abt...       0  \n",
       "3250  @stighefootball Begovic has been garbage. He g...       0  \n",
       "3251                 Wrecked today got my hattrick ????       0  \n",
       "\n",
       "[3237 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TESTING MODEL\n",
    "\n",
    "X_test_keyword_tfidf = tfidf_vectorizer_keyword.transform(test_df['keyword'])\n",
    "X_test_tweet_tfidf = tfidf_vectorizer_tweet.transform(test_df['text'])\n",
    "\n",
    "import scipy.sparse\n",
    "\n",
    "X_test_combined_tfidf = scipy.sparse.hstack((X_test_keyword_tfidf, X_test_tweet_tfidf))\n",
    "\n",
    "y_pred = clf.predict(X_test_combined_tfidf)\n",
    "\n",
    "test_df['target'] = y_pred\n",
    "sep_test_df = test_df\n",
    "sep_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f7bf5b",
   "metadata": {},
   "source": [
    "# Differences between combining keyword and text vs separating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92d9715c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of differences: 152\n"
     ]
    }
   ],
   "source": [
    "differences = (combined_test_df['target'] != sep_test_df['target']).sum()\n",
    "\n",
    "print(\"Number of differences:\", differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9866345f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
